[base]
seed = 0
experiment_name = "handwritten_digit_classification"

[logging]
level = "info"
format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

[model]
# We can use relative path (w.r.t. the conf.toml file) to the .py file
target = "model::SimpleCNN" 
input_dims = 1
layers = 4
dropout = 0.5
output_dims = 10

[training]
epochs = 1
epoch_schedulers = [
    {target = "torch.optim.lr_scheduler::CosineAnnealingLR", T_max = 100}
]
callbacks = [
    {target = "callbacks::SaveConfusionMatrixCallback",  task="multiclass", num_classes = 10, save_dir = "{{ PROJECT_DIR }}/cm"},
    {target = "lightning.pytorch.callbacks::DeviceStatsMonitor"}
]

# [training.checkpoint]
# path = "chckpt"
# monitor = {"metric" = "MyPrecision", "stage" = "val"}
# filename = "{epoch}_{val_myprecision:.2f}_cnn"
# mode = "max"
# save_top_k = 1

[training.optimizer]
target = "torch.optim::Adam"
lr = 0.001
weight_decay = 0.01

[training.criterion]
target = "torch.nn::CrossEntropyLoss"
weight = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]

[validation]
run_every_epoch = 1

[dataset]
target = "./datamodule.py::MNISTCustomDatamodule"

[dataset.trainval]
root_dir = "./mnist"

[dataset.train.loader]
batch_size = 150
shuffle = true
num_workers = 4

[dataset.validation.loader]
batch_size = 150
shuffle = false
num_workers = 4

[metrics]
MyPrecision = {target = "torchmetrics::Precision", task = "multiclass", num_classes=10}
FBetaScore = {target = "torchmetrics::FBetaScore", task = "multiclass", num_classes=10, beta = 0.1}