{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About","text":""},{"location":"index.html#a-quick-way-to-start-with-machine-and-deep-learning","title":"A quick way to start with machine and deep learning","text":"<p>News</p> <p>You can now overwrite configuration with command line options. See Overwriting configuration with CLI!</p> <p>News</p> <p>You can now define a custom train/validation split for experiments. See Defining custom splits!</p> <p>Kit4DL is a Python framework for simple, fast, and customisable deep learning prototyping and development. It uses PyTorch Lightning as a backend, since it is a powerful, yet quick-to-set-up, framework for deep learning pipelines management, and it relies on TOML (TOML format documentation can be found in https://toml.io/) configuration file. Though TOML is a relatively new format, it is gaining more and more attention in the Python ecosystem thanks to its intuitiveness, conciseness, and ease of reading. Furthermore, Kit4DL uses torchmetrics library for PyTorch-integrated and efficient implementation of a miscellaneous of metrics.</p>"},{"location":"index.html#authors","title":"\ud83d\udd8b\ufe0f Authors","text":"<ol> <li> <p>Jakub Walczak </p> </li> <li> <p>Marco Macini </p> </li> <li> <p>Mirko Stojiljkovic </p> </li> <li> <p>Shahbaz Alvi </p> </li> </ol>"},{"location":"index.html#acknowledgement","title":"\ud83d\ude4f Acknowledgement","text":"<p>This work has received fundings from the Polish National Centre for Research and Development under the LIDER XI program [grant number 0092/L-11/2019, \"Semantic analysis of 3D point clouds\"] and from the European Union\u2019s Horizon 2020 Research and Innovation programme [SILVANUS Project - grant agreement number 101037247].</p>"},{"location":"index.html#cite-us","title":"\ud83d\udcdc Cite Us","text":"<pre><code>@SOFTWARE{kit4dl,\n  author = {Walczak, Jakub and\n            Mancini, Marco and\n            Stojiljkovi\u0107, Mirko and\n            Alvi, Shahbaz},\n  title = {Kit4DL},\n  month = sep,\n  year = 2023,\n  note = {{Available in GitHub: https://github.com/opengeokube/kit4dl}},\n  publisher = {Zenodo},\n  version = {2023.9b1},\n  doi = {10.5281/zenodo.8328176},\n  url = {https://doi.org/10.5281/zenodo.8328176}\n}\n</code></pre>"},{"location":"cli.html","title":"Command Line Interface (CLI)","text":"<p>Kit4DL provides users with a conveninent CLI to create, run, or resume experiments.</p>"},{"location":"cli.html#creating-an-empty-project","title":"Creating an empty project","text":"<p>In order to create an empty project in the current working directory, use the following command:</p> <pre><code>kit4dl init\n</code></pre> <p>If you want to specify a custom name for the experiment directory, use <code>--name</code> option:</p> <pre><code>kit4dl init --name=my-custom-project\n</code></pre>"},{"location":"cli.html#running-train-validation-loop","title":"Running train-validation loop","text":"<p>To run the training just type the following command:</p> <pre><code>kit4dl train\n</code></pre> <p>If you want to run also test for best saved weight, use flag <code>--test</code>:</p> <pre><code>kit4dl train --test\n</code></pre>"},{"location":"cli.html#specifying-path-to-the-configuration-file","title":"Specifying path to the configuration file","text":"<pre><code>kit4dl train --conf=/path/to/your/conf.toml\n</code></pre> <p>Note: By default, Kit4DL searches for the <code>conf.toml</code> file in the current working directory. If you want to specify the other path or the name of your configuration file differs from the expected one (<code>conf.toml</code>), use <code>--config</code> option:</p>"},{"location":"cli.html#overwriting-configuration","title":"Overwriting configuration","text":"<p>Note</p> <p>Available since 2024.5b0</p> <p>You can overwrite any configuration option with CLI argument called <code>overwrite</code>.  Just specify a comma-separated string of options to replace. Nested keys are available using <code>.</code> (dot operator). Below, you can see an example.</p> <p>To overwrite logging level to <code>ERROR</code> and to change learning rate to <code>0.5</code>, just run</p> <pre><code>kit4dl train --conf=/path/to/your/conf.toml --overwrite \"logging.level=error,training.optimizer.lr=0.5\"\n</code></pre>"},{"location":"datamodule.html","title":"Specifying data module","text":"<p>               Bases: <code>ABC</code>, <code>LightningDataModule</code>, <code>LoggerMixin</code></p> <p>The class with the logic for dataset management.</p> <p>The class provides a user with a simple interface: <code>prepare_data</code> is a method for downloading and preprocessing datasets <code>prepare_traindatasets</code> is a method returning <code>torch.Dataset</code> for train     data <code>prepare_valdatasets</code> is a method returning <code>torch.Dataset</code> for validation     data <code>prepare_trainvaldatasets</code> is a method returning a tuple of two     <code>torch.Dataset</code>s for train and validation data     (if this method is provided, <code>prepare_traindatasets</code> and     <code>prepare_valdatasets</code> shouldn't be implemented) <code>prepare_testdataset</code> is a method returning <code>torch.Dataset</code> for test data <code>prepare_predictdataset</code> is a method returning <code>torch.Dataset</code> for data     for prediction</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def __init__(self, conf: DatasetConf):\n    super().__init__()\n    self.conf = conf\n    self.trainval_dataset_generator: (\n        Generator[tuple[Dataset, Dataset], None, None] | None\n    ) = None\n    self.train_dataset: Dataset | None = None\n    self.val_dataset: Dataset | None = None\n    self.test_dataset: Dataset | None = None\n    self.predict_dataset: Dataset | None = None\n    self._split_suffix = os.environ.get(\n        \"KIT4DL_SPLIT_PREFIX\", \"(split={:02d})\"\n    )\n    self._configure_logger()\n    for extra_arg_key, extra_arg_value in self.conf.arguments.items():\n        self.debug(\n            \"setting extra user-defined argument: %s:%s\",\n            extra_arg_key,\n            extra_arg_value,\n        )\n        setattr(self, extra_arg_key, extra_arg_value)\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_data","title":"prepare_data","text":"<pre><code>prepare_data()\n</code></pre> <p>Prepare dataset for train/validation/test/predict splits.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_data--examples","title":"Examples","text":"<pre><code>class MyDatamodule(Kit4DLAbstractDataModule):\n\n    def prepare_data(self):\n        # any logic you need to perform before creating splits\n        download_dataset()\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_data(self):\n    \"\"\"Prepare dataset for train/validation/test/predict splits.\n\n    Examples\n    --------\n    ```python\n    class MyDatamodule(Kit4DLAbstractDataModule):\n\n        def prepare_data(self):\n            # any logic you need to perform before creating splits\n            download_dataset()\n    ```\n    \"\"\"\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_traindataset","title":"prepare_traindataset","text":"<pre><code>prepare_traindataset(*args: Any, **kwargs: Any) -&gt; Dataset\n</code></pre> <p>Prepare dataset for training.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_traindataset--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the dataset *kwargs : Any     List of named arguments required to setup the dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_traindataset--returns","title":"Returns","text":"<p>train_dataset : Dataset     A training dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_traindataset--examples","title":"Examples","text":"<pre><code>...\ndef prepare_traindatasets(self, root_dir: str) -&gt; Dataset:\n    train_dset = MyDataset(root_dir=root_dir)\n    return train_dset\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_traindataset(self, *args: Any, **kwargs: Any) -&gt; Dataset:\n    \"\"\"Prepare dataset for training.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the dataset\n    **kwargs : Any\n        List of named arguments required to setup the dataset\n\n    Returns\n    -------\n    train_dataset : Dataset\n        A training dataset\n\n    Examples\n    --------\n    ```python\n    ...\n    def prepare_traindatasets(self, root_dir: str) -&gt; Dataset:\n        train_dset = MyDataset(root_dir=root_dir)\n        return train_dset\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_valdataset","title":"prepare_valdataset","text":"<pre><code>prepare_valdataset(*args: Any, **kwargs: Any) -&gt; Dataset\n</code></pre> <p>Prepare dataset for validation.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_valdataset--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the dataset *kwargs : Any     List of named arguments required to setup the dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_valdataset--returns","title":"Returns","text":"<p>val_dataset : Dataset     A validation dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_valdataset--examples","title":"Examples","text":"<pre><code>...\ndef prepare_valdatasets(self, root_dir: str) -&gt; Dataset:\n    val_dset = MyDataset(root_dir=root_dir)\n    return val_dset\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_valdataset(self, *args: Any, **kwargs: Any) -&gt; Dataset:\n    \"\"\"Prepare dataset for validation.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the dataset\n    **kwargs : Any\n        List of named arguments required to setup the dataset\n\n    Returns\n    -------\n    val_dataset : Dataset\n        A validation dataset\n\n    Examples\n    --------\n    ```python\n    ...\n    def prepare_valdatasets(self, root_dir: str) -&gt; Dataset:\n        val_dset = MyDataset(root_dir=root_dir)\n        return val_dset\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_trainvaldatasets","title":"prepare_trainvaldatasets","text":"<pre><code>prepare_trainvaldatasets(*args: Any, **kwargs: Any) -&gt; Generator[tuple[Dataset, Dataset], None, None]\n</code></pre> <p>Prepare dataset for training and validation.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_trainvaldatasets--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the dataset *kwargs : Any     List of named arguments required to setup the dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_trainvaldatasets--returns","title":"Returns","text":"<p>trainval_dataset_generators : tuple of two Datasets and a string     Tuple consisting of train and validation dataset, and a suffix     for the split</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_trainvaldatasets--examples","title":"Examples","text":"<pre><code>...\ndef prepare_trainvaldatasets(self, root_dir: str) -&gt; tuple[Dataset, Dataset]:\n    dset = MyDataset(root_dir=root_dir)\n    train_dset, val_dset = random_split(dset, [500, 50])\n    return train_dset, val_dset\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_trainvaldatasets(\n    self, *args: Any, **kwargs: Any\n) -&gt; Generator[tuple[Dataset, Dataset], None, None]:\n    \"\"\"Prepare dataset for training and validation.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the dataset\n    **kwargs : Any\n        List of named arguments required to setup the dataset\n\n    Returns\n    -------\n    trainval_dataset_generators : tuple of two Datasets and a string\n        Tuple consisting of train and validation dataset, and a suffix\n        for the split\n\n    Examples\n    --------\n    ```python\n    ...\n    def prepare_trainvaldatasets(self, root_dir: str) -&gt; tuple[Dataset, Dataset]:\n        dset = MyDataset(root_dir=root_dir)\n        train_dset, val_dset = random_split(dset, [500, 50])\n        return train_dset, val_dset\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_testdataset","title":"prepare_testdataset","text":"<pre><code>prepare_testdataset(*args: Any, **kwargs: Any) -&gt; Dataset\n</code></pre> <p>Prepare dataset for testing.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_testdataset--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the dataset *kwargs : Any     List of named arguments required to setup the dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_testdataset--returns","title":"Returns","text":"<p>test_datasets : Dataset     A test dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_testdataset--examples","title":"Examples","text":"<pre><code>...\ndef prepare_testdataset(self, root_dir: str) -&gt; Dataset:\n    return MyDataset(root_dir=root_dir)\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_testdataset(self, *args: Any, **kwargs: Any) -&gt; Dataset:\n    \"\"\"Prepare dataset for testing.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the dataset\n    **kwargs : Any\n        List of named arguments required to setup the dataset\n\n    Returns\n    -------\n    test_datasets : Dataset\n        A test dataset\n\n    Examples\n    --------\n    ```python\n    ...\n    def prepare_testdataset(self, root_dir: str) -&gt; Dataset:\n        return MyDataset(root_dir=root_dir)\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_predictdataset","title":"prepare_predictdataset","text":"<pre><code>prepare_predictdataset(*args: Any, **kwargs: Any) -&gt; Dataset\n</code></pre> <p>Prepare dataset for predicting.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_predictdataset--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the dataset *kwargs : Any     List of named arguments required to setup the dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_predictdataset--returns","title":"Returns","text":"<p>pred_datasets : Dataset     A prediction dataset</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.prepare_predictdataset--examples","title":"Examples","text":"<pre><code>...\ndef prepare_predictdataset(self, root_dir: str) -&gt; Dataset:\n    return MyDataset(root_dir=root_dir)\n</code></pre> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def prepare_predictdataset(self, *args: Any, **kwargs: Any) -&gt; Dataset:\n    \"\"\"Prepare dataset for predicting.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the dataset\n    **kwargs : Any\n        List of named arguments required to setup the dataset\n\n    Returns\n    -------\n    pred_datasets : Dataset\n        A prediction dataset\n\n    Examples\n    --------\n    ```python\n    ...\n    def prepare_predictdataset(self, root_dir: str) -&gt; Dataset:\n        return MyDataset(root_dir=root_dir)\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.setup","title":"setup","text":"<pre><code>setup(stage: str) -&gt; None\n</code></pre> <p>Set up data depending on the stage.</p> <p>The method should not be overriden unless necessary.</p>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.setup--parameters","title":"Parameters","text":"<p>stage : str     The stage of the pipeline. One out of <code>['fit', 'test', 'predict']</code></p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def setup(self, stage: str) -&gt; None:\n    \"\"\"Set up data depending on the stage.\n\n    The method should not be overriden unless necessary.\n\n    Parameters\n    ----------\n    stage : str\n        The stage of the pipeline. One out of `['fit', 'test', 'predict']`\n    \"\"\"\n    match stage:\n        case \"fit\":\n            self._handle_fit_stage()\n        case \"test\":\n            self._handle_test_stage()\n        case \"predict\":\n            self._handle_predict_stage()\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.get_collate_fn","title":"get_collate_fn","text":"<pre><code>get_collate_fn() -&gt; Callable | None\n</code></pre> <p>Get batch collate function.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def get_collate_fn(self) -&gt; Callable | None:\n    \"\"\"Get batch collate function.\"\"\"\n    return None\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.get_train_collate_fn","title":"get_train_collate_fn","text":"<pre><code>get_train_collate_fn() -&gt; Callable | None\n</code></pre> <p>Get train specific collate function.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def get_train_collate_fn(self) -&gt; Callable | None:\n    \"\"\"Get train specific collate function.\"\"\"\n    return self.get_collate_fn()\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.get_val_collate_fn","title":"get_val_collate_fn","text":"<pre><code>get_val_collate_fn() -&gt; Callable | None\n</code></pre> <p>Get validation specific collate function.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def get_val_collate_fn(self) -&gt; Callable | None:\n    \"\"\"Get validation specific collate function.\"\"\"\n    return self.get_collate_fn()\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.get_test_collate_fn","title":"get_test_collate_fn","text":"<pre><code>get_test_collate_fn() -&gt; Callable | None\n</code></pre> <p>Get test specific collate function.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def get_test_collate_fn(self) -&gt; Callable | None:\n    \"\"\"Get test specific collate function.\"\"\"\n    return self.get_collate_fn()\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.get_predict_collate_fn","title":"get_predict_collate_fn","text":"<pre><code>get_predict_collate_fn() -&gt; Callable | None\n</code></pre> <p>Get predict specific collate function.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def get_predict_collate_fn(self) -&gt; Callable | None:\n    \"\"\"Get predict specific collate function.\"\"\"\n    return self.get_collate_fn()\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.trainval_dataloaders","title":"trainval_dataloaders","text":"<pre><code>trainval_dataloaders() -&gt; Generator[tuple[DataLoader, DataLoader, str], None, None]\n</code></pre> <p>Prepare loader for train and validation data.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def trainval_dataloaders(\n    self,\n) -&gt; Generator[tuple[DataLoader, DataLoader, str], None, None]:\n    \"\"\"Prepare loader for train and validation data.\"\"\"\n    if self.conf.trainval:\n        assert self.trainval_dataset_generator is not None, (\n            \"did you forget to return `torch.utils.data.Dataset`instance\"\n            \" from the `prepare_trainvaldatasets` method?\"\n        )\n        assert self.conf.train is not None, (\n            \"[dataset.train.loader] section is is missing in the\"\n            \" configuration file.\"\n        )\n        assert self.conf.validation is not None, (\n            \"[dataset.validation.loader] section is is missing in the\"\n            \" configuration file.\"\n        )\n        assert (\n            self.conf.train.loader is not None\n            and self.conf.validation.loader is not None\n        ), (\n            \"did you forget to define [dataset.train.loader] and\"\n            \"[dataset.validation.loader] sections in the configuration \"\n            \"file?\"\n        )\n        for i, (tr_dataset, val_dataset) in enumerate(\n            self.trainval_dataset_generator\n        ):\n            yield DataLoader(\n                tr_dataset,\n                **self.conf.train.loader,\n                collate_fn=self.get_train_collate_fn(),\n            ), DataLoader(\n                val_dataset,\n                **self.conf.validation.loader,\n                collate_fn=self.get_val_collate_fn(),\n            ), self._split_suffix.format(\n                i + 1\n            )\n    elif self.conf.train and self.conf.validation:\n        yield self._train_dataloader(), self._val_dataloader(), \"\"\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.test_dataloader","title":"test_dataloader","text":"<pre><code>test_dataloader() -&gt; DataLoader\n</code></pre> <p>Prepare loader for test data.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def test_dataloader(self) -&gt; DataLoader:\n    \"\"\"Prepare loader for test data.\"\"\"\n    assert self.conf.test, (\n        \"test configuration is not defined. did you forget\"\n        \" [dataset.test] section in the configuration file?\"\n    )\n    assert self.test_dataset is not None, (\n        \"did you forget to return `torch.utils.data.Dataset` instance\"\n        \" from the `prepare_testdataset` method?\"\n    )\n    return DataLoader(\n        self.test_dataset,\n        **self.conf.test.loader,\n        collate_fn=self.get_test_collate_fn(),\n    )\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.predict_dataloader","title":"predict_dataloader","text":"<pre><code>predict_dataloader() -&gt; DataLoader\n</code></pre> <p>Prepare loader for prediction data.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def predict_dataloader(self) -&gt; DataLoader:\n    \"\"\"Prepare loader for prediction data.\"\"\"\n    assert self.conf.predict, (\n        \"validation configuration is not defined. did you forget\"\n        \" [dataset.predict] section in the configuration file?\"\n    )\n    assert self.predict_dataset is not None, (\n        \"did you forget to return `torch.utils.data.Dataset` instance\"\n        \" from the `prepare_predictdataset` method?\"\n    )\n    return DataLoader(\n        self.predict_dataset,\n        **self.conf.predict.loader,\n        collate_fn=self.get_predict_collate_fn(),\n    )\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.numpy_train_dataloader","title":"numpy_train_dataloader","text":"<pre><code>numpy_train_dataloader()\n</code></pre> <p>Prepare loader for train data for models accepting <code>numpy.ndarray</code>.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def numpy_train_dataloader(self):\n    \"\"\"Prepare loader for train data for models accepting `numpy.ndarray`.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.numpy_val_dataloader","title":"numpy_val_dataloader","text":"<pre><code>numpy_val_dataloader()\n</code></pre> <p>Prepare loader for val data for models accepting <code>numpy.ndarray</code>.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def numpy_val_dataloader(self):\n    \"\"\"Prepare loader for val data for models accepting `numpy.ndarray`.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.numpy_testdataloader","title":"numpy_testdataloader","text":"<pre><code>numpy_testdataloader()\n</code></pre> <p>Prepare loader for test data for models accepting <code>numpy.ndarray</code>.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def numpy_testdataloader(self):\n    \"\"\"Prepare loader for test data for models accepting `numpy.ndarray`.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#kit4dl.nn.dataset.Kit4DLAbstractDataModule.numpy_predictdataloader","title":"numpy_predictdataloader","text":"<pre><code>numpy_predictdataloader()\n</code></pre> <p>Prepare loader for pred data for models accepting <code>numpy.ndarray</code>.</p> Source code in <code>kit4dl/nn/dataset.py</code> <pre><code>def numpy_predictdataloader(self):\n    \"\"\"Prepare loader for pred data for models accepting `numpy.ndarray`.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"datamodule.html#custom-splits","title":"Custom splits","text":"<p>Note</p> <p>Available since 2024.5b0</p> <p>n Kit4DL, you can easily define the logic for cross-validation. Starting from the version 2024.5b0 the old method <code>prepare_trainvaldataset</code> was replaced by the <code>prepare_trainvaldatasets</code> method that is a generator. You define the logic of the generator by yourself. To run 10-fold cross validation, implement the method in the following way:</p> <pre><code>...\nfrom sklearn.model_selection import KFold\n\nclass MNISTCustomDatamodule(Kit4DLAbstractDataModule):\n    def prepare_trainvaldatasets(self, root_dir: str):\n        dset = MNIST(\n            root=root_dir,\n            train=True,\n            download=True,\n            transform=transforms.ToTensor(),\n        )\n        split = KFold(n_splits=10, shuffle=True, random_state=0)\n        for i, (train_ind, val_ind) in enumerate(\n            split.split(dset.data, dset.targets)\n        ):\n            yield Subset(dset, train_ind), Subset(dset, val_ind)\n</code></pre> <p>If you want to stick to the old logic and return a single split, just <code>yield</code> the corresponding datasets:</p> <pre><code>...\n\nclass MNISTCustomDatamodule(Kit4DLAbstractDataModule):\n    def prepare_trainvaldatasets(self, root_dir: str):\n        tr_dset = MNIST(\n            root=root_dir,\n            train=True,\n            download=True,\n            transform=transforms.ToTensor(),\n        )\n        ts_dset = MNIST(\n            root=root_dir,\n            train=False,\n            download=True,\n            transform=transforms.ToTensor(),\n        )        \n        yield tr_dset, ts_dset\n</code></pre> <p>Each generated tuple of train and validation dataset will be fed into the training/validation pipeline. If you use external metric loggers, results for each split will be uploaded using the experiment name and the suffix like <code>(split=0)</code>.</p> <p>The suffix can be overwriten by the environmental variable <code>KIT4DL_SPLIT_PREFIX</code>.        </p>"},{"location":"installation.html","title":"Installation","text":"<p>Kit4DL is available for all operating systems for Python in versions 3.10 and 3.11. </p>"},{"location":"installation.html#install-from-anaconda","title":"Install from Anaconda","text":"<pre><code>conda install -c conda-forge kit4dl \n</code></pre>"},{"location":"installation.html#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install kit4dl \n</code></pre>"},{"location":"installation.html#contributing","title":"\ud83e\udde4 Contributing","text":"<p>All contributions are welcome. To do so, just clone repository install, and contribute:</p> <pre><code>git clone https://github.com/opengeokube/kit4dl\ncd kit4dl\nconda env create -f dev-env.yaml\npip install -e .\n</code></pre>"},{"location":"nn.html","title":"Dealing with Neural Networks","text":"<p>               Bases: <code>ABC</code>, <code>LightningModule</code>, <code>LoggerMixin</code></p> <p>Base abstract class for Kit4DL modules.</p> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    super().__init__()\n    self.configure(*args, **kwargs)\n    self.save_hyperparameters()\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.configure","title":"configure  <code>abstractmethod</code>","text":"<pre><code>configure(*args: Any, **kwargs: Any) -&gt; None\n</code></pre> <p>Configure the architecture of the neural network.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.configure--parameters","title":"Parameters","text":"<p>args: Any     List of positional arguments to setup the network architecture *kwargs : Any     List of named arguments required to setup the network architecture</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.configure--examples","title":"Examples","text":"<pre><code>def configure(self, input_dims, output_dims) -&gt; None:\n    self.fc1 = nn.Sequential(\n        nn.Linear(input_dims, output_dims),\n    )\n</code></pre> Source code in <code>kit4dl/nn/base.py</code> <pre><code>@abstractmethod\ndef configure(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Configure the architecture of the neural network.\n\n    Parameters\n    ----------\n    *args: Any\n        List of positional arguments to setup the network architecture\n    **kwargs : Any\n        List of named arguments required to setup the network architecture\n\n    Examples\n    --------\n    ```python\n    def configure(self, input_dims, output_dims) -&gt; None:\n        self.fc1 = nn.Sequential(\n            nn.Linear(input_dims, output_dims),\n        )\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_step","title":"run_step  <code>abstractmethod</code>","text":"<pre><code>run_step(batch, batch_idx) -&gt; tuple[Tensor, ...]\n</code></pre> <p>Carry out single train/validation/test step for the given <code>batch</code>.</p> <p>Return a tuple of two <code>torch.Tensor</code>'s: true labels and predicted scores. If you need to define separate logic for validation or test step, implement <code>val_step</code> or <code>test_step</code> methods, respectivelly.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_step--parameters","title":"Parameters","text":"<p>batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor     The output of the Dataloader batch_idx : int     Index of the batch</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_step--returns","title":"Returns","text":"<p>result : tuple of <code>torch.Tensor</code>     A tuple of 2 or 3 items:     - if a tuple of 2 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,     - if a tuple of 3 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,         4. <code>torch.Tensor</code> with loss value.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_step--examples","title":"Examples","text":"<pre><code>...\ndef run_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    return (label_input, scores)\n</code></pre> <pre><code>...\ndef run_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    loss = super().compute_loss(prediction=logits, target=is_fire)\n    return (label_input, scores, loss)\n</code></pre> Source code in <code>kit4dl/nn/base.py</code> <pre><code>@abstractmethod\ndef run_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    \"\"\"Carry out single train/validation/test step for the given `batch`.\n\n    Return a tuple of two `torch.Tensor`'s: true labels and predicted scores.\n    If you need to define separate logic for validation or test step,\n    implement `val_step` or `test_step` methods, respectivelly.\n\n    Parameters\n    ----------\n    batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor\n        The output of the Dataloader\n    batch_idx : int\n        Index of the batch\n\n    Returns\n    -------\n    result : tuple of `torch.Tensor`\n        A tuple of 2 or 3 items:\n        - if a tuple of 2 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n        - if a tuple of 3 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n            4. `torch.Tensor` with loss value.\n\n    Examples\n    --------\n    ```python\n    ...\n    def run_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        return (label_input, scores)\n    ```\n\n    ```python\n    ...\n    def run_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        loss = super().compute_loss(prediction=logits, target=is_fire)\n        return (label_input, scores, loss)\n    ```\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_val_step","title":"run_val_step","text":"<pre><code>run_val_step(batch, batch_idx) -&gt; tuple[Tensor, ...]\n</code></pre> <p>Carry out single validation step for the given <code>batch</code>.</p> <p>Return a tuple of two <code>torch.Tensor</code>'s: true labels and predicted scores. If you need to define separate logic for validation or test step, implement <code>val_step</code> or <code>test_step</code> methods, respectivelly.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_val_step--parameters","title":"Parameters","text":"<p>batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor     The output of the Dataloader batch_idx : int     Index of the batch</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_val_step--returns","title":"Returns","text":"<p>result : tuple of <code>torch.Tensor</code>     A tuple of 2 or 3 items:     - if a tuple of 2 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,     - if a tuple of 3 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,         4. <code>torch.Tensor</code> with loss value.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_val_step--examples","title":"Examples","text":"<pre><code>...\ndef run_val_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    return (label_input, scores)\n</code></pre> <pre><code>...\ndef run_val_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    loss = super().compute_loss(prediction=logits, target=is_fire)\n    return (label_input, scores, loss)\n</code></pre> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def run_val_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    \"\"\"Carry out single validation step for the given `batch`.\n\n    Return a tuple of two `torch.Tensor`'s: true labels and predicted scores.\n    If you need to define separate logic for validation or test step,\n    implement `val_step` or `test_step` methods, respectivelly.\n\n    Parameters\n    ----------\n    batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor\n        The output of the Dataloader\n    batch_idx : int\n        Index of the batch\n\n    Returns\n    -------\n    result : tuple of `torch.Tensor`\n        A tuple of 2 or 3 items:\n        - if a tuple of 2 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n        - if a tuple of 3 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n            4. `torch.Tensor` with loss value.\n\n    Examples\n    --------\n    ```python\n    ...\n    def run_val_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        return (label_input, scores)\n    ```\n\n    ```python\n    ...\n    def run_val_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        loss = super().compute_loss(prediction=logits, target=is_fire)\n        return (label_input, scores, loss)\n    ```\n    \"\"\"\n    return self.run_step(batch, batch_idx)\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_test_step","title":"run_test_step","text":"<pre><code>run_test_step(batch, batch_idx) -&gt; tuple[Tensor, ...]\n</code></pre> <p>Carry out single test step for the given <code>batch</code>.</p> <p>Return a tuple of two <code>torch.Tensor</code>'s: true labels and predicted scores. If you need to define separate logic for validation or test step, implement <code>val_step</code> or <code>test_step</code> methods, respectivelly.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_test_step--parameters","title":"Parameters","text":"<p>batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor     The output of the Dataloader batch_idx : int     Index of the batch</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_test_step--returns","title":"Returns","text":"<p>result : tuple of <code>torch.Tensor</code>     A tuple of 2 or 3items:     - if a tuple of 2 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,     - if a tuple of 3 elements:         1. <code>torch.Tensor</code> of ground-truth labels,         2. <code>torch.Tensor</code> output of the network,         4. <code>torch.Tensor</code> with loss value.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_test_step--examples","title":"Examples","text":"<pre><code>...\ndef run_test_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    return (label_input, scores)\n</code></pre> <pre><code>...\ndef run_test_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    feature_input, label_input = batch\n    scores = self(feature_input)\n    loss = super().compute_loss(prediction=logits, target=is_fire)\n    return (label_input, scores, loss)\n</code></pre> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def run_test_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n    \"\"\"Carry out single test step for the given `batch`.\n\n    Return a tuple of two `torch.Tensor`'s: true labels and predicted scores.\n    If you need to define separate logic for validation or test step,\n    implement `val_step` or `test_step` methods, respectivelly.\n\n    Parameters\n    ----------\n    batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor\n        The output of the Dataloader\n    batch_idx : int\n        Index of the batch\n\n    Returns\n    -------\n    result : tuple of `torch.Tensor`\n        A tuple of 2 or 3items:\n        - if a tuple of 2 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n        - if a tuple of 3 elements:\n            1. `torch.Tensor` of ground-truth labels,\n            2. `torch.Tensor` output of the network,\n            4. `torch.Tensor` with loss value.\n\n    Examples\n    --------\n    ```python\n    ...\n    def run_test_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor,  ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        return (label_input, scores)\n    ```\n\n    ```python\n    ...\n    def run_test_step(self, batch, batch_idx) -&gt; tuple[torch.Tensor, ...]:\n        feature_input, label_input = batch\n        scores = self(feature_input)\n        loss = super().compute_loss(prediction=logits, target=is_fire)\n        return (label_input, scores, loss)\n    ```\n    \"\"\"\n    return self.run_step(batch, batch_idx)\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_predict_step","title":"run_predict_step","text":"<pre><code>run_predict_step(batch, batch_idx) -&gt; Tensor\n</code></pre> <p>Carry out single predict step for the given <code>batch</code>.</p> <p>Return a <code>torch.Tensor</code> - the predicted scores. If not overriden, the implementation of <code>step</code> method is used.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_predict_step--parameters","title":"Parameters","text":"<p>batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor     The output of the Dataloader batch_idx : int     Index of the batch</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_predict_step--returns","title":"Returns","text":"<p>result : torch.Tensor     The score being the output of of the network</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_predict_step--note","title":"Note","text":"<p>The function returns just score values as for prediction we do not have the ground-truth labels.</p>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.run_predict_step--examples","title":"Examples","text":"<pre><code>...\ndef run_predict_step(self, batch, batch_idx) -&gt; torch.Tensor:\n    feature_input = batch\n    return self(feature_input)\n</code></pre> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def run_predict_step(self, batch, batch_idx) -&gt; torch.Tensor:\n    \"\"\"Carry out single predict step for the given `batch`.\n\n    Return a `torch.Tensor` - the predicted scores.\n    If not overriden, the implementation of `step` method is used.\n\n    Parameters\n    ----------\n    batch : torch.Tensor or tuple of torch.Tensor or list of torch.Tensor\n        The output of the Dataloader\n    batch_idx : int\n        Index of the batch\n\n    Returns\n    -------\n    result : torch.Tensor\n        The score being the output of of the network\n\n\n    Note\n    ----\n    The function returns just score values as for prediction we do not have\n    the ground-truth labels.\n\n    Examples\n    --------\n    ```python\n    ...\n    def run_predict_step(self, batch, batch_idx) -&gt; torch.Tensor:\n        feature_input = batch\n        return self(feature_input)\n    ```\n    \"\"\"\n    _, scores = self.run_step(batch, batch_idx)\n    return scores\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(prediction: Tensor, target: Tensor) -&gt; Tensor\n</code></pre> <p>Compute the loss based on the prediction and target.</p> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def compute_loss(\n    self, prediction: torch.Tensor, target: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"Compute the loss based on the prediction and target.\"\"\"\n    assert self.criterion.is_defined, \"criterion is not defined\"\n    return self.criterion(prediction, target)\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.training_step","title":"training_step","text":"<pre><code>training_step(batch, batch_idx)\n</code></pre> <p>Carry out a single training step.</p> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def training_step(\n    self, batch, batch_idx\n):  # pylint: disable=arguments-differ\n    \"\"\"Carry out a single training step.\"\"\"\n    res = self.run_step(batch, batch_idx)\n    match res:\n        case (y_true, y_scores):\n            loss = self.compute_loss(y_scores, y_true)\n        case (y_true, y_scores, loss):\n            pass\n        case _:\n            self.error(\"wrong size of tuple returned by `run_step`\")\n            raise ValueError(\"wrong size of tuple returned by `run_step`\")\n    return self._prepare_step_output(pred=y_scores, true=y_true, loss=loss)\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.validation_step","title":"validation_step","text":"<pre><code>validation_step(batch, batch_idx)\n</code></pre> <p>Carry out a single validation step.</p> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def validation_step(\n    self, batch, batch_idx\n):  # pylint: disable=arguments-differ\n    \"\"\"Carry out a single validation step.\"\"\"\n    res = self.run_val_step(batch, batch_idx)\n    match res:\n        case (y_true, y_scores):\n            loss = self.compute_loss(y_scores, y_true)\n        case (y_true, y_scores, loss):\n            pass\n        case _:\n            self.error(\"wrong size of tuple returned by `run_step`\")\n            raise ValueError(\"wrong size of tuple returned by `run_step`\")\n    return self._prepare_step_output(pred=y_scores, true=y_true, loss=loss)\n</code></pre>"},{"location":"nn.html#kit4dl.nn.base.Kit4DLAbstractModule.test_step","title":"test_step","text":"<pre><code>test_step(batch, batch_idx)\n</code></pre> <p>Carry out a single test step.</p> Source code in <code>kit4dl/nn/base.py</code> <pre><code>def test_step(self, batch, batch_idx):  # pylint: disable=arguments-differ\n    \"\"\"Carry out a single test step.\"\"\"\n    res = self.run_test_step(batch, batch_idx)\n    match res:\n        case (y_true, y_scores):\n            loss = self.compute_loss(y_scores, y_true)\n        case (y_true, y_scores, loss):\n            pass\n        case _:\n            self.error(\"wrong size of tuple returned by `run_step`\")\n            raise ValueError(\"wrong size of tuple returned by `run_step`\")\n    return self._prepare_step_output(pred=y_scores, true=y_true, loss=loss)\n</code></pre>"},{"location":"quick.html","title":"Quick start","text":"<p>Below, you can find quick start quide for Kit4DL.</p>"},{"location":"quick.html#step-1-create-a-virtual-environment","title":"Step 1. Create a virtual environment","text":"<p>You can use <code>venv</code> built-it package:</p> <p><pre><code>python -m venv ai\n</code></pre> and activate it using appropriate file in <code>ai/bin</code> directory.</p> <p>You can also use conda environments:</p> <p><pre><code>conda create -n ai python=3.11\n</code></pre> and activate it using the command</p> <pre><code>conda activate ai\n</code></pre>"},{"location":"quick.html#step-2-install-kit4dl","title":"Step 2. Install Kit4DL","text":"<p>Either using <code>PyPI</code> repository:</p> <pre><code>pip install kit4dl \n</code></pre> <p>or using Anaconda repository:</p> <pre><code>conda install -c conda-forge kit4dl\n</code></pre>"},{"location":"quick.html#step-3-prepare-an-empty-kit4dl-project","title":"Step 3. Prepare an empty Kit4DL project:","text":"<pre><code>kit4dl init --name=my-first-project # (1)!\n</code></pre> <ol> <li>Parameter <code>--name</code> is optional and, by default, takes value <code>new_kit4dl_project</code></li> </ol>"},{"location":"quick.html#step-4-prepare-toml-configuration-file","title":"Step 4. Prepare TOML configuration file","text":"<p>All configuration stuff related to ANN learning, validation and testing is managed by the configuration file in TOML format. When you create an empty Kit4DL project, you'll get example config.toml file with the following structure:</p> <pre><code>[base] # (1)!\nseed = 0 # (2)!\ncuda_id = 0 # (3)!\nexperiment_name = \"my_new_awesome_experiment\" # (4)!\n\n[logging] # (5)!\ntype = \"comet\" # (6)!\nlevel = \"info\" # (7)!\nformat = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" # (8)!\n\n\n[model] # (9)!\ntarget = \"./model.py::MyNewNetwork\" # (10)!\narg1 = \"...\" # (11)!\narg2 = \"...\"\n\n[training] # (12)!\nepochs = 100 # (13)!\nepoch_schedulers = [ # (14)!\n    {target = \"torch.optim.lr_scheduler::CosineAnnealingLR\", T_max=100}\n]\n\n[training.checkpoint] # (15)!\npath = \"my_checkpoints\" # (16)!\nmonitor = {metric = \"MyScore\", stage = \"val\"} # (17)!\nfilename = \"{epoch}_{val_myscore:.2f}_some_name\" # (18)!\nmode = \"max\" # (19)!\nsave_top_k = 1\n\n[training.optimizer]\ntarget = \"torch.optim::Adam\" # (20)!\nlr = 0.0001 # (21)!\nweight_decay = 0.03\n\n[training.criterion]\ntarget = \"torch.nn::NLLLoss\" # (22)!\nweight = [0.1, 0.9] # (23)!\n\n[validation]\nrun_every_epoch = 1 # (24)!\n\n[dataset]\ntarget = \"./datamodule.py::MyCustomDatamodule\" # (25)!\n\n[dataset.trainval] # (26)!\narg1 = 10 # (27)!\narg2 = ...\n\n[dataset.train] # (28)!\nroot_dir = \"my_train_file.txt\" # (29)!\n\n[dataset.validation]\nroot_dir = \"my_val_file.txt\"\n\n[dataset.train.loader] # (30)!\nbatch_size = 10 # (31)!\nshuffle = true\nnum_workers = 4\n\n[dataset.validation.loader] # (32)!\nbatch_size = 10\nshuffle = false\nnum_workers = 4\n\n[dataset.test.loader] # (33)!\nbatch_size = 10\nshuffle = false\nnum_workers = 4\n\n[metrics] # (34)!\nMyScore = { \n    target = \"torchmetrics::Precision\",  # (35)!\n    task = \"multiclass\", # (36)!\n    num_classes = 10}  \nMySecondScore = {target = \"torchmetrics::FBetaScore\", task = \"multiclass\", num_classes = 10, beta = 0.1} \n</code></pre> <ol> <li>The section with base setup.</li> <li>Seed for pseudorandom numbers generator (to enable reproducibility).</li> <li>CUDA device ID to use (if you have just one GPU installed, use <code>0</code>). To use CPU for learning, remove that line.</li> <li>Experiment name to use throughout the learning/logging process. Basically, it can be any text you want.</li> <li>Section for logging setup.</li> <li>One of supported logging services to use (\"comet\", \"csv\", \"mlflow\", \"neptune\", \"tensorboard\", \"wandb\"). If not set, <code>csv</code> will be used.</li> <li>Logging level for Python logger (\"debug\", \"info\", \"warn\", \"error\").</li> <li>Logging format according to Python logging documentation. Use supported attributes.</li> <li>ANN-model related configuration.</li> <li>Path to the subclass of <code>Kit4DLAbstractModule</code>. If can be an absolute or relative path followed by class name (e.g. <code>./model.py::MyNewNetwork</code>). If the class is importable, you can specify its fully qualified name (e.g. <code>some_package.some_module.MyNewNetwork</code>).</li> <li>If you class <code>MyNewNetwork</code> have some parameters, you can specify them here (e.g. number of layers, number of hidden units, etc).</li> <li>The section with trening-specific configuration.</li> <li>Quite self-explanatory: number of epochs :)</li> <li>If you want to specify some epochs schedulers, you can add <code>epoch_schedulers</code> attribute in the configuration file. It should be a list of dictionaries. Each dictionary should have <code>target</code> attribute indicating a class to the scheduler, and - if needed - other arguments required by the scheduler class indicated in <code>target</code> property.</li> <li>You can specify model checkpointing!</li> <li>Directory where checkpoints should be saved.</li> <li>Attribute to indicate which metric should be tracked for checkpointing (e.g. to save the model with the best accuracy) and for which phase (suuported phases are: <code>train</code>, <code>val</code>).</li> <li>Pattern for saved checkpoint as indicated here. You can use metric defined in <code>[metric]</code> section using the pattern <code>&lt;stage&gt;_&lt;lowercase metric name&gt;</code> (e.g. <code>val_myscore</code>).</li> <li>You can also define some other arguments accepted by ModelCheckpoint</li> <li>Path to the optimizer class.</li> <li>The optimizer-specify arguments can be specified as extra attributes in the section.</li> <li>Path to the criterion class</li> <li>Weights for criterion specified as list of floats.</li> <li>How frequently validation should be run.</li> <li>Path to the subclass of <code>Kit4DLAbstractDataModule</code></li> <li>If there is a common procedure for generating train/validation sSlit like random split the input data, you can define arguments in the section [dataset.trainval]. </li> <li>Arguments for the <code>prepare_trainvaldataset</code> method of you subclass of <code>Kit4DLAbstractDataModule</code> might be passed as extra attributes in this section.</li> <li>If you want to specify different logic for train and validation datasets like loading separate formerly prepared files, you can use separate sections [dataset.train] and [dataset.validation].</li> <li>This is a sample argument passed to <code>prepare_traindataset</code> of you subclass of <code>Kit4DLAbstractDataModule</code>.</li> <li>Section for configuration of data loader for train dataset.</li> <li>You can define all arguments accepted by pytorch DataLoader</li> <li>Similarily for validation data loader...</li> <li>... and the test one.</li> <li>The section contains metric used for evaluate model, save checkpoints, and store in services like Comet.ml. Each metric is a dictionary whose key must be an only-letter text without white signs...</li> <li><code>target</code> key for a metric should indicate a subclass of <code>torchmetric.Metric</code> base class or one of the metrics defined in <code>torchmetric</code> package (e.g. <code>torchmetrics::Precision</code>).</li> <li>Some extra arguments required by the given metric can be specified as other items in the dictionary.</li> </ol>"}]}